{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "06930ed9-1048-4b32-b3b8-9794d4618929",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv1D, \\\n",
    "    AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D, Dropout, Softmax\n",
    "from tensorflow.keras.models import Sequential\n",
    "from keras.models import Model\n",
    "from keras.initializers import glorot_uniform\n",
    "from tensorflow import keras\n",
    "from numpy import genfromtxt\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.python.keras.callbacks import TensorBoard\n",
    "import os\n",
    "\n",
    "from keras import backend as K\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c0341f83-79db-4d18-8c66-0a6e9728857c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500000, 120)\n",
      "(500000, 90)\n",
      "(16800, 120)\n",
      "(16800, 90)\n"
     ]
    }
   ],
   "source": [
    "# SNR\n",
    "Training_Data = genfromtxt('Training_Data.csv', delimiter=\",\")\n",
    "Training_Data = np.array(Training_Data)\n",
    "#Training_Data = Training_Data[...,None]\n",
    "print(Training_Data.shape)\n",
    "\n",
    "Training_Labels = genfromtxt('Training_Labels.csv', delimiter=\",\")\n",
    "Training_Labels = np.array(Training_Labels)\n",
    "#Training_Labels = Training_Labels[...,None]\n",
    "print(Training_Labels.shape)\n",
    "\n",
    "Testing_Data = genfromtxt('Testing_Data.csv', delimiter=\",\")\n",
    "Testing_Data = np.array(Testing_Data)\n",
    "#Testing_Data = Testing_Data[...,None]\n",
    "print(Testing_Data.shape)\n",
    "\n",
    "Testing_Labels = genfromtxt('Testing_Labels.csv', delimiter=\",\")\n",
    "Testing_Labels = np.array(Testing_Labels)\n",
    "#Testing_Labels = Testing_Labels[...,None]\n",
    "print(Testing_Labels.shape)\n",
    "\n",
    "\n",
    "indices_1 = np.arange(Training_Data.shape[0])\n",
    "np.random.shuffle(indices_1)\n",
    "Training_Data = Training_Data[indices_1]\n",
    "Training_Labels = Training_Labels[indices_1]\n",
    "\n",
    "indices_2 = np.arange(Testing_Data.shape[0])\n",
    "np.random.shuffle(indices_2)\n",
    "Testing_Data = Testing_Data[indices_2]\n",
    "Testing_Labels = Testing_Labels[indices_2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f6ecb393-38b3-465a-a92a-c9a911c15b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = [\n",
    "    keras.metrics.TruePositives(name='tp'),\n",
    "    keras.metrics.FalsePositives(name='fp'),\n",
    "    keras.metrics.TrueNegatives(name='tn'),\n",
    "    keras.metrics.FalseNegatives(name='fn'),\n",
    "    keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "    keras.metrics.Precision(name='precision'),\n",
    "    keras.metrics.Recall(name='recall'),\n",
    "    keras.metrics.AUC(name='auc'),\n",
    "    keras.metrics.F1Score(name='f1_score'),\n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ff6daa41-2b0b-4596-b420-d0b0c0d39f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model architecture\n",
    "model = Sequential([\n",
    "    Dense(480, activation='relu', input_shape=(120,)),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.2),\n",
    "    Dense(240, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.2),\n",
    "    Dense(120, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dense(90, activation='sigmoid')  # Sigmoid activation for multi-label output\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "              loss='binary_crossentropy',metrics=metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "97360bb9-8a6a-44f8-8833-7051e4e83e69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "990/990 [==============================] - 6s 4ms/step - loss: 0.1381 - tp: 3025147.0000 - fp: 1357049.0000 - tn: 38737936.0000 - fn: 1429853.0000 - accuracy: 0.9374 - precision: 0.6903 - recall: 0.6790 - auc: 0.9683 - f1_score: 0.0399 - val_loss: 0.0133 - val_tp: 42832.0000 - val_fp: 79.0000 - val_tn: 404921.0000 - val_fn: 2168.0000 - val_accuracy: 0.9950 - val_precision: 0.9982 - val_recall: 0.9518 - val_auc: 0.9998 - val_f1_score: 0.0433\n",
      "Epoch 2/20\n",
      "990/990 [==============================] - 4s 4ms/step - loss: 0.0101 - tp: 4353522.0000 - fp: 38269.0000 - tn: 40056728.0000 - fn: 101478.0000 - accuracy: 0.9969 - precision: 0.9913 - recall: 0.9772 - auc: 0.9995 - f1_score: 0.0439 - val_loss: 0.0019 - val_tp: 44762.0000 - val_fp: 10.0000 - val_tn: 404990.0000 - val_fn: 238.0000 - val_accuracy: 0.9994 - val_precision: 0.9998 - val_recall: 0.9947 - val_auc: 1.0000 - val_f1_score: 0.0426\n",
      "Epoch 3/20\n",
      "990/990 [==============================] - 4s 4ms/step - loss: 0.0050 - tp: 4406613.0000 - fp: 18824.0000 - tn: 40076192.0000 - fn: 48387.0000 - accuracy: 0.9985 - precision: 0.9957 - recall: 0.9891 - auc: 0.9996 - f1_score: 0.0449 - val_loss: 0.0010 - val_tp: 44886.0000 - val_fp: 11.0000 - val_tn: 404989.0000 - val_fn: 114.0000 - val_accuracy: 0.9997 - val_precision: 0.9998 - val_recall: 0.9975 - val_auc: 1.0000 - val_f1_score: 0.0429\n",
      "Epoch 4/20\n",
      "990/990 [==============================] - 4s 4ms/step - loss: 0.0036 - tp: 4420185.0000 - fp: 14082.0000 - tn: 40080904.0000 - fn: 34815.0000 - accuracy: 0.9989 - precision: 0.9968 - recall: 0.9922 - auc: 0.9997 - f1_score: 0.0491 - val_loss: 5.8350e-04 - val_tp: 44945.0000 - val_fp: 8.0000 - val_tn: 404992.0000 - val_fn: 55.0000 - val_accuracy: 0.9999 - val_precision: 0.9998 - val_recall: 0.9988 - val_auc: 1.0000 - val_f1_score: 0.0440\n",
      "Epoch 5/20\n",
      "990/990 [==============================] - 4s 4ms/step - loss: 0.0030 - tp: 4426425.0000 - fp: 12244.0000 - tn: 40082760.0000 - fn: 28575.0000 - accuracy: 0.9991 - precision: 0.9972 - recall: 0.9936 - auc: 0.9997 - f1_score: 0.0576 - val_loss: 7.1883e-04 - val_tp: 44907.0000 - val_fp: 18.0000 - val_tn: 404982.0000 - val_fn: 93.0000 - val_accuracy: 0.9998 - val_precision: 0.9996 - val_recall: 0.9979 - val_auc: 1.0000 - val_f1_score: 0.0477\n",
      "Epoch 6/20\n",
      "990/990 [==============================] - 4s 4ms/step - loss: 0.0027 - tp: 4429903.0000 - fp: 11197.0000 - tn: 40083784.0000 - fn: 25097.0000 - accuracy: 0.9992 - precision: 0.9975 - recall: 0.9944 - auc: 0.9997 - f1_score: 0.0697 - val_loss: 4.6432e-04 - val_tp: 44942.0000 - val_fp: 11.0000 - val_tn: 404989.0000 - val_fn: 58.0000 - val_accuracy: 0.9998 - val_precision: 0.9998 - val_recall: 0.9987 - val_auc: 1.0000 - val_f1_score: 0.0532\n",
      "Epoch 7/20\n",
      "990/990 [==============================] - 4s 4ms/step - loss: 0.0023 - tp: 4433187.0000 - fp: 10094.0000 - tn: 40084928.0000 - fn: 21813.0000 - accuracy: 0.9993 - precision: 0.9977 - recall: 0.9951 - auc: 0.9998 - f1_score: 0.0833 - val_loss: 6.4659e-04 - val_tp: 44916.0000 - val_fp: 13.0000 - val_tn: 404987.0000 - val_fn: 84.0000 - val_accuracy: 0.9998 - val_precision: 0.9997 - val_recall: 0.9981 - val_auc: 1.0000 - val_f1_score: 0.0640\n",
      "Epoch 8/20\n",
      "990/990 [==============================] - 4s 4ms/step - loss: 0.0021 - tp: 4434931.0000 - fp: 9328.0000 - tn: 40085676.0000 - fn: 20069.0000 - accuracy: 0.9993 - precision: 0.9979 - recall: 0.9955 - auc: 0.9998 - f1_score: 0.0960 - val_loss: 2.0717e-04 - val_tp: 44982.0000 - val_fp: 3.0000 - val_tn: 404997.0000 - val_fn: 18.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9996 - val_auc: 1.0000 - val_f1_score: 0.0625\n",
      "Epoch 9/20\n",
      "990/990 [==============================] - 4s 4ms/step - loss: 0.0019 - tp: 4436976.0000 - fp: 8555.0000 - tn: 40086456.0000 - fn: 18024.0000 - accuracy: 0.9994 - precision: 0.9981 - recall: 0.9960 - auc: 0.9998 - f1_score: 0.1072 - val_loss: 5.3506e-04 - val_tp: 44943.0000 - val_fp: 20.0000 - val_tn: 404980.0000 - val_fn: 57.0000 - val_accuracy: 0.9998 - val_precision: 0.9996 - val_recall: 0.9987 - val_auc: 1.0000 - val_f1_score: 0.0868\n",
      "Epoch 10/20\n",
      "990/990 [==============================] - 4s 4ms/step - loss: 0.0018 - tp: 4437933.0000 - fp: 8208.0000 - tn: 40086780.0000 - fn: 17067.0000 - accuracy: 0.9994 - precision: 0.9982 - recall: 0.9962 - auc: 0.9998 - f1_score: 0.1170 - val_loss: 4.8770e-04 - val_tp: 44955.0000 - val_fp: 26.0000 - val_tn: 404974.0000 - val_fn: 45.0000 - val_accuracy: 0.9998 - val_precision: 0.9994 - val_recall: 0.9990 - val_auc: 1.0000 - val_f1_score: 0.0998\n",
      "Epoch 11/20\n",
      "990/990 [==============================] - 4s 4ms/step - loss: 0.0017 - tp: 4438863.0000 - fp: 7879.0000 - tn: 40087104.0000 - fn: 16137.0000 - accuracy: 0.9995 - precision: 0.9982 - recall: 0.9964 - auc: 0.9998 - f1_score: 0.1251 - val_loss: 3.7316e-04 - val_tp: 44964.0000 - val_fp: 15.0000 - val_tn: 404985.0000 - val_fn: 36.0000 - val_accuracy: 0.9999 - val_precision: 0.9997 - val_recall: 0.9992 - val_auc: 1.0000 - val_f1_score: 0.1211\n",
      "Epoch 12/20\n",
      "990/990 [==============================] - 4s 4ms/step - loss: 0.0016 - tp: 4440124.0000 - fp: 7475.0000 - tn: 40087528.0000 - fn: 14876.0000 - accuracy: 0.9995 - precision: 0.9983 - recall: 0.9967 - auc: 0.9998 - f1_score: 0.1311 - val_loss: 2.7511e-04 - val_tp: 44972.0000 - val_fp: 6.0000 - val_tn: 404994.0000 - val_fn: 28.0000 - val_accuracy: 0.9999 - val_precision: 0.9999 - val_recall: 0.9994 - val_auc: 1.0000 - val_f1_score: 0.1118\n",
      "Epoch 13/20\n",
      "990/990 [==============================] - 4s 4ms/step - loss: 0.0015 - tp: 4440985.0000 - fp: 6961.0000 - tn: 40088028.0000 - fn: 14015.0000 - accuracy: 0.9995 - precision: 0.9984 - recall: 0.9969 - auc: 0.9998 - f1_score: 0.1366 - val_loss: 1.8939e-04 - val_tp: 44988.0000 - val_fp: 5.0000 - val_tn: 404995.0000 - val_fn: 12.0000 - val_accuracy: 1.0000 - val_precision: 0.9999 - val_recall: 0.9997 - val_auc: 1.0000 - val_f1_score: 0.1224\n",
      "Epoch 14/20\n",
      "990/990 [==============================] - 4s 4ms/step - loss: 0.0014 - tp: 4441838.0000 - fp: 6575.0000 - tn: 40088444.0000 - fn: 13162.0000 - accuracy: 0.9996 - precision: 0.9985 - recall: 0.9970 - auc: 0.9999 - f1_score: 0.1422 - val_loss: 2.3799e-04 - val_tp: 44970.0000 - val_fp: 1.0000 - val_tn: 404999.0000 - val_fn: 30.0000 - val_accuracy: 0.9999 - val_precision: 1.0000 - val_recall: 0.9993 - val_auc: 1.0000 - val_f1_score: 0.1278\n",
      "Epoch 15/20\n",
      "990/990 [==============================] - 4s 4ms/step - loss: 0.0014 - tp: 4442478.0000 - fp: 6311.0000 - tn: 40088672.0000 - fn: 12522.0000 - accuracy: 0.9996 - precision: 0.9986 - recall: 0.9972 - auc: 0.9999 - f1_score: 0.1467 - val_loss: 2.0388e-04 - val_tp: 44977.0000 - val_fp: 5.0000 - val_tn: 404995.0000 - val_fn: 23.0000 - val_accuracy: 0.9999 - val_precision: 0.9999 - val_recall: 0.9995 - val_auc: 1.0000 - val_f1_score: 0.1433\n",
      "Epoch 16/20\n",
      "990/990 [==============================] - 4s 4ms/step - loss: 0.0013 - tp: 4443118.0000 - fp: 6160.0000 - tn: 40088820.0000 - fn: 11882.0000 - accuracy: 0.9996 - precision: 0.9986 - recall: 0.9973 - auc: 0.9999 - f1_score: 0.1508 - val_loss: 9.3446e-04 - val_tp: 44909.0000 - val_fp: 5.0000 - val_tn: 404995.0000 - val_fn: 91.0000 - val_accuracy: 0.9998 - val_precision: 0.9999 - val_recall: 0.9980 - val_auc: 0.9997 - val_f1_score: 0.1552\n",
      "Epoch 17/20\n",
      "990/990 [==============================] - 4s 4ms/step - loss: 0.0012 - tp: 4443721.0000 - fp: 5657.0000 - tn: 40089360.0000 - fn: 11279.0000 - accuracy: 0.9996 - precision: 0.9987 - recall: 0.9975 - auc: 0.9999 - f1_score: 0.1541 - val_loss: 2.4718e-04 - val_tp: 44974.0000 - val_fp: 10.0000 - val_tn: 404990.0000 - val_fn: 26.0000 - val_accuracy: 0.9999 - val_precision: 0.9998 - val_recall: 0.9994 - val_auc: 1.0000 - val_f1_score: 0.1551\n",
      "Epoch 18/20\n",
      "990/990 [==============================] - 4s 4ms/step - loss: 0.0012 - tp: 4443686.0000 - fp: 5859.0000 - tn: 40089108.0000 - fn: 11314.0000 - accuracy: 0.9996 - precision: 0.9987 - recall: 0.9975 - auc: 0.9999 - f1_score: 0.1567 - val_loss: 2.0784e-04 - val_tp: 44974.0000 - val_fp: 7.0000 - val_tn: 404993.0000 - val_fn: 26.0000 - val_accuracy: 0.9999 - val_precision: 0.9998 - val_recall: 0.9994 - val_auc: 1.0000 - val_f1_score: 0.1546\n",
      "Epoch 19/20\n",
      "990/990 [==============================] - 4s 4ms/step - loss: 0.0011 - tp: 4444696.0000 - fp: 5302.0000 - tn: 40089704.0000 - fn: 10304.0000 - accuracy: 0.9997 - precision: 0.9988 - recall: 0.9977 - auc: 0.9999 - f1_score: 0.1599 - val_loss: 1.3145e-04 - val_tp: 44985.0000 - val_fp: 2.0000 - val_tn: 404998.0000 - val_fn: 15.0000 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 0.9997 - val_auc: 1.0000 - val_f1_score: 0.1555\n",
      "Epoch 20/20\n",
      "990/990 [==============================] - 4s 4ms/step - loss: 0.0012 - tp: 4444626.0000 - fp: 5413.0000 - tn: 40089560.0000 - fn: 10374.0000 - accuracy: 0.9996 - precision: 0.9988 - recall: 0.9977 - auc: 0.9999 - f1_score: 0.1621 - val_loss: 2.7076e-04 - val_tp: 44968.0000 - val_fp: 7.0000 - val_tn: 404993.0000 - val_fn: 32.0000 - val_accuracy: 0.9999 - val_precision: 0.9998 - val_recall: 0.9993 - val_auc: 1.0000 - val_f1_score: 0.1744\n",
      "525/525 [==============================] - 1s 2ms/step - loss: 0.0018 - tp: 150560.0000 - fp: 12.0000 - tn: 1360788.0000 - fn: 640.0000 - accuracy: 0.9996 - precision: 0.9999 - recall: 0.9958 - auc: 0.9994 - f1_score: 0.1795\n"
     ]
    }
   ],
   "source": [
    "batch = 500\n",
    "epoch = 20\n",
    "\n",
    "history = model.fit(Training_Data, Training_Labels, validation_split=0.01, epochs=epoch, batch_size=batch,\n",
    "                      shuffle=True, verbose=1)\n",
    "preds = model.evaluate(Testing_Data, Testing_Labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0af83ab3-c2fc-43a7-b5df-d50314533d6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.001843539415858686\n",
      "TP = 150560.0\n",
      "FP = 12.0\n",
      "TN = 1360788.0\n",
      "FN = 640.0\n",
      "BinaryAccuracy = 0.99956876039505\n",
      "Precision = 0.9999203085899353\n",
      "Recall = 0.9957671761512756\n",
      "AUC = 0.9994267225265503\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_16 (Dense)            (None, 480)               58080     \n",
      "                                                                 \n",
      " batch_normalization_12 (Ba  (None, 480)               1920      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 480)               0         \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 240)               115440    \n",
      "                                                                 \n",
      " batch_normalization_13 (Ba  (None, 240)               960       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 240)               0         \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 120)               28920     \n",
      "                                                                 \n",
      " batch_normalization_14 (Ba  (None, 120)               480       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 90)                10890     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 216690 (846.45 KB)\n",
      "Trainable params: 215010 (839.88 KB)\n",
      "Non-trainable params: 1680 (6.56 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "print(\"loss = \" + str(preds[0]))\n",
    "print(\"TP = \" + str(preds[1]))\n",
    "print(\"FP = \" + str(preds[2]))\n",
    "print(\"TN = \" + str(preds[3]))\n",
    "print(\"FN = \" + str(preds[4]))\n",
    "print(\"BinaryAccuracy = \" + str(preds[5]))\n",
    "print(\"Precision = \" + str(preds[6]))\n",
    "print(\"Recall = \" + str(preds[7]))\n",
    "print(\"AUC = \" + str(preds[8]))\n",
    "#print(\"f1_score = \" + str(preds[9]))\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bdff195-60b0-4f82-8f38-ab3f7a5227ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
