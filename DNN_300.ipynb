{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "06930ed9-1048-4b32-b3b8-9794d4618929",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv1D, \\\n",
    "    AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D, Dropout, Softmax\n",
    "from tensorflow.keras.models import Sequential\n",
    "from keras.models import Model\n",
    "from keras.initializers import glorot_uniform\n",
    "from tensorflow import keras\n",
    "from numpy import genfromtxt\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.python.keras.callbacks import TensorBoard\n",
    "import os\n",
    "\n",
    "from keras import backend as K\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c0341f83-79db-4d18-8c66-0a6e9728857c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(700000, 60)\n",
      "(700000, 90)\n",
      "(18400, 60)\n",
      "(18400, 90)\n"
     ]
    }
   ],
   "source": [
    "# SNR\n",
    "Training_Data = genfromtxt('Training_Data.csv', delimiter=\",\")\n",
    "Training_Data = np.array(Training_Data)\n",
    "#Training_Data = Training_Data[...,None]\n",
    "print(Training_Data.shape)\n",
    "\n",
    "Training_Labels = genfromtxt('Training_Labels.csv', delimiter=\",\")\n",
    "Training_Labels = np.array(Training_Labels)\n",
    "#Training_Labels = Training_Labels[...,None]\n",
    "print(Training_Labels.shape)\n",
    "\n",
    "Testing_Data = genfromtxt('Testing_Data.csv', delimiter=\",\")\n",
    "Testing_Data = np.array(Testing_Data)\n",
    "#Testing_Data = Testing_Data[...,None]\n",
    "print(Testing_Data.shape)\n",
    "\n",
    "Testing_Labels = genfromtxt('Testing_Labels.csv', delimiter=\",\")\n",
    "Testing_Labels = np.array(Testing_Labels)\n",
    "#Testing_Labels = Testing_Labels[...,None]\n",
    "print(Testing_Labels.shape)\n",
    "\n",
    "\n",
    "indices_1 = np.arange(Training_Data.shape[0])\n",
    "np.random.shuffle(indices_1)\n",
    "Training_Data = Training_Data[indices_1]\n",
    "Training_Labels = Training_Labels[indices_1]\n",
    "\n",
    "indices_2 = np.arange(Testing_Data.shape[0])\n",
    "np.random.shuffle(indices_2)\n",
    "Testing_Data = Testing_Data[indices_2]\n",
    "Testing_Labels = Testing_Labels[indices_2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f6ecb393-38b3-465a-a92a-c9a911c15b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = [\n",
    "    keras.metrics.TruePositives(name='tp'),\n",
    "    keras.metrics.FalsePositives(name='fp'),\n",
    "    keras.metrics.TrueNegatives(name='tn'),\n",
    "    keras.metrics.FalseNegatives(name='fn'),\n",
    "    keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "    keras.metrics.Precision(name='precision'),\n",
    "    keras.metrics.Recall(name='recall'),\n",
    "    keras.metrics.AUC(name='auc'),\n",
    "    keras.metrics.F1Score(name='f1_score'),\n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ff6daa41-2b0b-4596-b420-d0b0c0d39f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model architecture\n",
    "model = Sequential([\n",
    "    Dense(240, activation='relu', input_shape=(60,)),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.2),\n",
    "    Dense(120, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.2),\n",
    "    Dense(60, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dense(90, activation='sigmoid')  # Sigmoid activation for multi-label output\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "              loss='binary_crossentropy',metrics=metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "97360bb9-8a6a-44f8-8833-7051e4e83e69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1386/1386 [==============================] - 8s 4ms/step - loss: 0.1441 - tp: 3868972.0000 - fp: 1795955.0000 - tn: 54337064.0000 - fn: 2368028.0000 - accuracy: 0.9332 - precision: 0.6830 - recall: 0.6203 - auc: 0.9642 - f1_score: 0.0388 - val_loss: 0.0209 - val_tp: 57187.0000 - val_fp: 194.0000 - val_tn: 566806.0000 - val_fn: 5813.0000 - val_accuracy: 0.9905 - val_precision: 0.9966 - val_recall: 0.9077 - val_auc: 0.9996 - val_f1_score: 0.0419\n",
      "Epoch 2/20\n",
      "1386/1386 [==============================] - 6s 4ms/step - loss: 0.0190 - tp: 5935582.0000 - fp: 155281.0000 - tn: 55977752.0000 - fn: 301418.0000 - accuracy: 0.9927 - precision: 0.9745 - recall: 0.9517 - auc: 0.9988 - f1_score: 0.0425 - val_loss: 0.0040 - val_tp: 62470.0000 - val_fp: 58.0000 - val_tn: 566942.0000 - val_fn: 530.0000 - val_accuracy: 0.9991 - val_precision: 0.9991 - val_recall: 0.9916 - val_auc: 0.9999 - val_f1_score: 0.0395\n",
      "Epoch 3/20\n",
      "1386/1386 [==============================] - 6s 4ms/step - loss: 0.0083 - tp: 6115702.0000 - fp: 42107.0000 - tn: 56090948.0000 - fn: 121298.0000 - accuracy: 0.9974 - precision: 0.9932 - recall: 0.9806 - auc: 0.9993 - f1_score: 0.0442 - val_loss: 0.0024 - val_tp: 62679.0000 - val_fp: 55.0000 - val_tn: 566945.0000 - val_fn: 321.0000 - val_accuracy: 0.9994 - val_precision: 0.9991 - val_recall: 0.9949 - val_auc: 0.9996 - val_f1_score: 0.0403\n",
      "Epoch 4/20\n",
      "1386/1386 [==============================] - 6s 4ms/step - loss: 0.0061 - tp: 6150870.0000 - fp: 30285.0000 - tn: 56102668.0000 - fn: 86130.0000 - accuracy: 0.9981 - precision: 0.9951 - recall: 0.9862 - auc: 0.9994 - f1_score: 0.0533 - val_loss: 0.0011 - val_tp: 62837.0000 - val_fp: 20.0000 - val_tn: 566980.0000 - val_fn: 163.0000 - val_accuracy: 0.9997 - val_precision: 0.9997 - val_recall: 0.9974 - val_auc: 0.9999 - val_f1_score: 0.0421\n",
      "Epoch 5/20\n",
      "1386/1386 [==============================] - 6s 4ms/step - loss: 0.0049 - tp: 6169838.0000 - fp: 24492.0000 - tn: 56108472.0000 - fn: 67162.0000 - accuracy: 0.9985 - precision: 0.9960 - recall: 0.9892 - auc: 0.9995 - f1_score: 0.0698 - val_loss: 8.5653e-04 - val_tp: 62867.0000 - val_fp: 26.0000 - val_tn: 566974.0000 - val_fn: 133.0000 - val_accuracy: 0.9997 - val_precision: 0.9996 - val_recall: 0.9979 - val_auc: 1.0000 - val_f1_score: 0.0472\n",
      "Epoch 6/20\n",
      "1386/1386 [==============================] - 6s 4ms/step - loss: 0.0042 - tp: 6179880.0000 - fp: 21313.0000 - tn: 56111656.0000 - fn: 57120.0000 - accuracy: 0.9987 - precision: 0.9966 - recall: 0.9908 - auc: 0.9995 - f1_score: 0.0872 - val_loss: 8.5769e-04 - val_tp: 62852.0000 - val_fp: 22.0000 - val_tn: 566978.0000 - val_fn: 148.0000 - val_accuracy: 0.9997 - val_precision: 0.9997 - val_recall: 0.9977 - val_auc: 1.0000 - val_f1_score: 0.0608\n",
      "Epoch 7/20\n",
      "1386/1386 [==============================] - 6s 4ms/step - loss: 0.0038 - tp: 6186148.0000 - fp: 19465.0000 - tn: 56113512.0000 - fn: 50852.0000 - accuracy: 0.9989 - precision: 0.9969 - recall: 0.9918 - auc: 0.9995 - f1_score: 0.1013 - val_loss: 8.4677e-04 - val_tp: 62849.0000 - val_fp: 15.0000 - val_tn: 566985.0000 - val_fn: 151.0000 - val_accuracy: 0.9997 - val_precision: 0.9998 - val_recall: 0.9976 - val_auc: 1.0000 - val_f1_score: 0.0611\n",
      "Epoch 8/20\n",
      "1386/1386 [==============================] - 6s 4ms/step - loss: 0.0034 - tp: 6190937.0000 - fp: 17691.0000 - tn: 56115352.0000 - fn: 46063.0000 - accuracy: 0.9990 - precision: 0.9972 - recall: 0.9926 - auc: 0.9996 - f1_score: 0.1127 - val_loss: 5.8800e-04 - val_tp: 62907.0000 - val_fp: 19.0000 - val_tn: 566981.0000 - val_fn: 93.0000 - val_accuracy: 0.9998 - val_precision: 0.9997 - val_recall: 0.9985 - val_auc: 1.0000 - val_f1_score: 0.0660\n",
      "Epoch 9/20\n",
      "1386/1386 [==============================] - 6s 4ms/step - loss: 0.0033 - tp: 6193327.0000 - fp: 17433.0000 - tn: 56115592.0000 - fn: 43673.0000 - accuracy: 0.9990 - precision: 0.9972 - recall: 0.9930 - auc: 0.9996 - f1_score: 0.1216 - val_loss: 0.0013 - val_tp: 62840.0000 - val_fp: 12.0000 - val_tn: 566988.0000 - val_fn: 160.0000 - val_accuracy: 0.9997 - val_precision: 0.9998 - val_recall: 0.9975 - val_auc: 0.9996 - val_f1_score: 0.0843\n",
      "Epoch 10/20\n",
      "1386/1386 [==============================] - 6s 4ms/step - loss: 0.0031 - tp: 6195546.0000 - fp: 16696.0000 - tn: 56116280.0000 - fn: 41454.0000 - accuracy: 0.9991 - precision: 0.9973 - recall: 0.9934 - auc: 0.9996 - f1_score: 0.1278 - val_loss: 8.8828e-04 - val_tp: 62817.0000 - val_fp: 15.0000 - val_tn: 566985.0000 - val_fn: 183.0000 - val_accuracy: 0.9997 - val_precision: 0.9998 - val_recall: 0.9971 - val_auc: 0.9999 - val_f1_score: 0.1087\n",
      "Epoch 11/20\n",
      "1386/1386 [==============================] - 6s 4ms/step - loss: 0.0029 - tp: 6198255.0000 - fp: 15289.0000 - tn: 56117732.0000 - fn: 38745.0000 - accuracy: 0.9991 - precision: 0.9975 - recall: 0.9938 - auc: 0.9996 - f1_score: 0.1340 - val_loss: 5.5027e-04 - val_tp: 62912.0000 - val_fp: 11.0000 - val_tn: 566989.0000 - val_fn: 88.0000 - val_accuracy: 0.9998 - val_precision: 0.9998 - val_recall: 0.9986 - val_auc: 1.0000 - val_f1_score: 0.0955\n",
      "Epoch 12/20\n",
      "1386/1386 [==============================] - 6s 4ms/step - loss: 0.0028 - tp: 6200321.0000 - fp: 14787.0000 - tn: 56118156.0000 - fn: 36679.0000 - accuracy: 0.9992 - precision: 0.9976 - recall: 0.9941 - auc: 0.9996 - f1_score: 0.1383 - val_loss: 8.6457e-04 - val_tp: 62874.0000 - val_fp: 20.0000 - val_tn: 566980.0000 - val_fn: 126.0000 - val_accuracy: 0.9998 - val_precision: 0.9997 - val_recall: 0.9980 - val_auc: 0.9998 - val_f1_score: 0.1156\n",
      "Epoch 13/20\n",
      "1386/1386 [==============================] - 6s 4ms/step - loss: 0.0028 - tp: 6200870.0000 - fp: 14615.0000 - tn: 56118360.0000 - fn: 36130.0000 - accuracy: 0.9992 - precision: 0.9976 - recall: 0.9942 - auc: 0.9996 - f1_score: 0.1418 - val_loss: 4.3356e-04 - val_tp: 62922.0000 - val_fp: 5.0000 - val_tn: 566995.0000 - val_fn: 78.0000 - val_accuracy: 0.9999 - val_precision: 0.9999 - val_recall: 0.9988 - val_auc: 1.0000 - val_f1_score: 0.1289\n",
      "Epoch 14/20\n",
      "1386/1386 [==============================] - 6s 4ms/step - loss: 0.0026 - tp: 6203055.0000 - fp: 13668.0000 - tn: 56119384.0000 - fn: 33945.0000 - accuracy: 0.9992 - precision: 0.9978 - recall: 0.9946 - auc: 0.9997 - f1_score: 0.1455 - val_loss: 4.0884e-04 - val_tp: 62926.0000 - val_fp: 11.0000 - val_tn: 566989.0000 - val_fn: 74.0000 - val_accuracy: 0.9999 - val_precision: 0.9998 - val_recall: 0.9988 - val_auc: 1.0000 - val_f1_score: 0.1172\n",
      "Epoch 15/20\n",
      "1386/1386 [==============================] - 6s 4ms/step - loss: 0.0026 - tp: 6203373.0000 - fp: 13835.0000 - tn: 56119152.0000 - fn: 33627.0000 - accuracy: 0.9992 - precision: 0.9978 - recall: 0.9946 - auc: 0.9997 - f1_score: 0.1486 - val_loss: 3.5416e-04 - val_tp: 62932.0000 - val_fp: 3.0000 - val_tn: 566997.0000 - val_fn: 68.0000 - val_accuracy: 0.9999 - val_precision: 1.0000 - val_recall: 0.9989 - val_auc: 1.0000 - val_f1_score: 0.1252\n",
      "Epoch 16/20\n",
      "1386/1386 [==============================] - 6s 4ms/step - loss: 0.0024 - tp: 6205687.0000 - fp: 12860.0000 - tn: 56120176.0000 - fn: 31313.0000 - accuracy: 0.9993 - precision: 0.9979 - recall: 0.9950 - auc: 0.9997 - f1_score: 0.1517 - val_loss: 9.7269e-04 - val_tp: 62861.0000 - val_fp: 15.0000 - val_tn: 566985.0000 - val_fn: 139.0000 - val_accuracy: 0.9998 - val_precision: 0.9998 - val_recall: 0.9978 - val_auc: 0.9998 - val_f1_score: 0.1411\n",
      "Epoch 17/20\n",
      "1386/1386 [==============================] - 6s 4ms/step - loss: 0.0024 - tp: 6205891.0000 - fp: 12810.0000 - tn: 56120224.0000 - fn: 31109.0000 - accuracy: 0.9993 - precision: 0.9979 - recall: 0.9950 - auc: 0.9997 - f1_score: 0.1543 - val_loss: 3.9024e-04 - val_tp: 62934.0000 - val_fp: 6.0000 - val_tn: 566994.0000 - val_fn: 66.0000 - val_accuracy: 0.9999 - val_precision: 0.9999 - val_recall: 0.9990 - val_auc: 1.0000 - val_f1_score: 0.1421\n",
      "Epoch 18/20\n",
      "1386/1386 [==============================] - 6s 4ms/step - loss: 0.0023 - tp: 6207121.0000 - fp: 12338.0000 - tn: 56120640.0000 - fn: 29879.0000 - accuracy: 0.9993 - precision: 0.9980 - recall: 0.9952 - auc: 0.9997 - f1_score: 0.1569 - val_loss: 4.2725e-04 - val_tp: 62929.0000 - val_fp: 23.0000 - val_tn: 566977.0000 - val_fn: 71.0000 - val_accuracy: 0.9999 - val_precision: 0.9996 - val_recall: 0.9989 - val_auc: 1.0000 - val_f1_score: 0.1414\n",
      "Epoch 19/20\n",
      "1386/1386 [==============================] - 6s 4ms/step - loss: 0.0023 - tp: 6207632.0000 - fp: 12290.0000 - tn: 56120744.0000 - fn: 29368.0000 - accuracy: 0.9993 - precision: 0.9980 - recall: 0.9953 - auc: 0.9997 - f1_score: 0.1591 - val_loss: 3.9669e-04 - val_tp: 62916.0000 - val_fp: 4.0000 - val_tn: 566996.0000 - val_fn: 84.0000 - val_accuracy: 0.9999 - val_precision: 0.9999 - val_recall: 0.9987 - val_auc: 1.0000 - val_f1_score: 0.1616\n",
      "Epoch 20/20\n",
      "1386/1386 [==============================] - 6s 4ms/step - loss: 0.0022 - tp: 6209065.0000 - fp: 11603.0000 - tn: 56121360.0000 - fn: 27935.0000 - accuracy: 0.9994 - precision: 0.9981 - recall: 0.9955 - auc: 0.9997 - f1_score: 0.1612 - val_loss: 2.8154e-04 - val_tp: 62958.0000 - val_fp: 2.0000 - val_tn: 566998.0000 - val_fn: 42.0000 - val_accuracy: 0.9999 - val_precision: 1.0000 - val_recall: 0.9993 - val_auc: 1.0000 - val_f1_score: 0.1565\n",
      "575/575 [==============================] - 2s 2ms/step - loss: 0.0015 - tp: 164833.0000 - fp: 2.0000 - tn: 1490398.0000 - fn: 767.0000 - accuracy: 0.9995 - precision: 1.0000 - recall: 0.9954 - auc: 0.9996 - f1_score: 0.1630\n"
     ]
    }
   ],
   "source": [
    "batch = 500\n",
    "epoch = 20\n",
    "\n",
    "history = model.fit(Training_Data, Training_Labels, validation_split=0.01, epochs=epoch, batch_size=batch,\n",
    "                      shuffle=True, verbose=1)\n",
    "preds = model.evaluate(Testing_Data, Testing_Labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0af83ab3-c2fc-43a7-b5df-d50314533d6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.0015285570407286286\n",
      "TP = 164833.0\n",
      "FP = 2.0\n",
      "TN = 1490398.0\n",
      "FN = 767.0\n",
      "BinaryAccuracy = 0.9995356202125549\n",
      "Precision = 0.9999878406524658\n",
      "Recall = 0.9953683614730835\n",
      "AUC = 0.999648928642273\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_24 (Dense)            (None, 240)               14640     \n",
      "                                                                 \n",
      " batch_normalization_18 (Ba  (None, 240)               960       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_12 (Dropout)        (None, 240)               0         \n",
      "                                                                 \n",
      " dense_25 (Dense)            (None, 120)               28920     \n",
      "                                                                 \n",
      " batch_normalization_19 (Ba  (None, 120)               480       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_13 (Dropout)        (None, 120)               0         \n",
      "                                                                 \n",
      " dense_26 (Dense)            (None, 60)                7260      \n",
      "                                                                 \n",
      " batch_normalization_20 (Ba  (None, 60)                240       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dense_27 (Dense)            (None, 90)                5490      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 57990 (226.52 KB)\n",
      "Trainable params: 57150 (223.24 KB)\n",
      "Non-trainable params: 840 (3.28 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "print(\"loss = \" + str(preds[0]))\n",
    "print(\"TP = \" + str(preds[1]))\n",
    "print(\"FP = \" + str(preds[2]))\n",
    "print(\"TN = \" + str(preds[3]))\n",
    "print(\"FN = \" + str(preds[4]))\n",
    "print(\"BinaryAccuracy = \" + str(preds[5]))\n",
    "print(\"Precision = \" + str(preds[6]))\n",
    "print(\"Recall = \" + str(preds[7]))\n",
    "print(\"AUC = \" + str(preds[8]))\n",
    "#print(\"f1_score = \" + str(preds[9]))\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bdff195-60b0-4f82-8f38-ab3f7a5227ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
