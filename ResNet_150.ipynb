{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed0fbdaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-10 10:57:39.802092: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-12-10 10:57:40.957659: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-12-10 10:57:40.957689: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-12-10 10:57:41.086696: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-12-10 10:57:41.352484: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv1D, \\\n",
    "    AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D, Dropout, Softmax\n",
    "from keras.models import Model\n",
    "from keras.initializers import glorot_uniform\n",
    "from tensorflow import keras\n",
    "from numpy import genfromtxt\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.python.keras.callbacks import TensorBoard\n",
    "import os\n",
    "\n",
    "from keras import backend as K\n",
    "\n",
    "\n",
    "def fro_norm(w):\n",
    "    return K.sqrt(K.sum(K.square(K.abs(w))))\n",
    "\n",
    "\n",
    "def cust_reg(w):\n",
    "    m = K.dot(K.transpose(w), w) - np.eye(w.shape)\n",
    "    return fro_norm(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f1d3e75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500000, 120)\n",
      "(500000, 90)\n",
      "(16800, 120)\n",
      "(16800, 90)\n"
     ]
    }
   ],
   "source": [
    "# SNR\n",
    "Training_Data = genfromtxt('Training_Data.csv', delimiter=\",\")\n",
    "Training_Data = np.array(Training_Data)\n",
    "#Training_Data = Training_Data[...,None]\n",
    "print(Training_Data.shape)\n",
    "\n",
    "Training_Labels = genfromtxt('Training_Labels.csv', delimiter=\",\")\n",
    "Training_Labels = np.array(Training_Labels)\n",
    "#Training_Labels = Training_Labels[...,None]\n",
    "print(Training_Labels.shape)\n",
    "\n",
    "Testing_Data = genfromtxt('Testing_Data.csv', delimiter=\",\")\n",
    "Testing_Data = np.array(Testing_Data)\n",
    "#Testing_Data = Testing_Data[...,None]\n",
    "print(Testing_Data.shape)\n",
    "\n",
    "Testing_Labels = genfromtxt('Testing_Labels.csv', delimiter=\",\")\n",
    "Testing_Labels = np.array(Testing_Labels)\n",
    "#Testing_Labels = Testing_Labels[...,None]\n",
    "print(Testing_Labels.shape)\n",
    "\n",
    "\n",
    "indices_1 = np.arange(Training_Data.shape[0])\n",
    "np.random.shuffle(indices_1)\n",
    "Training_Data = Training_Data[indices_1]\n",
    "Training_Labels = Training_Labels[indices_1]\n",
    "\n",
    "indices_2 = np.arange(Testing_Data.shape[0])\n",
    "np.random.shuffle(indices_2)\n",
    "Testing_Data = Testing_Data[indices_2]\n",
    "Testing_Labels = Testing_Labels[indices_2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "200d246a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def identity_block_1(X):\n",
    "    X_shortcut = X\n",
    "\n",
    "    X = Dense(960, activation=None, kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization()(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = Dropout(0.2)(X)\n",
    "    X = Dense(480, activation='relu', kernel_initializer=glorot_uniform(seed=0))(X) #252\n",
    "    X = BatchNormalization()(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = Dense(240, activation='relu', kernel_initializer=glorot_uniform(seed=0), bias_regularizer='l2', kernel_regularizer='l2')(X) #126\n",
    "    X = BatchNormalization()(X)\n",
    "    X = Dense(120, activation='relu', kernel_initializer=glorot_uniform(seed=0))(X) #252\n",
    "    X = BatchNormalization()(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    # Final step: Add shortcut value to main path, and pass it through a RELU activation\n",
    "    X = Add()([X, X_shortcut])\n",
    "\n",
    "    return X\n",
    "\n",
    "\n",
    "def ResNet(input_shape=(120,)):\n",
    "    # Define the input as a tensor with shape input_shape\n",
    "\n",
    "    X_input = Input(input_shape)\n",
    "    X = Dense(120, activation=None, kernel_initializer=glorot_uniform(seed=0))(X_input)\n",
    "    X = BatchNormalization()(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    # Adding identity block\n",
    "    X = identity_block_1(X)\n",
    "    X = identity_block_1(X)\n",
    "    X = identity_block_1(X)\n",
    "    X = identity_block_1(X)\n",
    "\n",
    "    # output layer\n",
    "    X = Flatten()(X)\n",
    "    X = Dense(90, activation='sigmoid', kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "\n",
    "    # Create model\n",
    "    model = Model(inputs=X_input, outputs=X, name='ResNet')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df57fcbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-10 10:59:05.205189: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 31141 MB memory:  -> device: 0, name: Tesla V100-SXM2-32GB, pci bus id: 0000:62:00.0, compute capability: 7.0\n"
     ]
    }
   ],
   "source": [
    "metrics = [\n",
    "    keras.metrics.TruePositives(name='tp'),\n",
    "    keras.metrics.FalsePositives(name='fp'),\n",
    "    keras.metrics.TrueNegatives(name='tn'),\n",
    "    keras.metrics.FalseNegatives(name='fn'),\n",
    "    keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "    keras.metrics.Precision(name='precision'),\n",
    "    keras.metrics.Recall(name='recall'),\n",
    "    keras.metrics.AUC(name='auc'),\n",
    "\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb50138c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-10 10:59:21.095857: I external/local_xla/xla/service/service.cc:168] XLA service 0x7eea61dc4810 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-12-10 10:59:21.095877: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0\n",
      "2024-12-10 10:59:21.127787: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-12-10 10:59:21.433751: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8907\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1733821161.558658 4142879 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "990/990 [==============================] - 30s 12ms/step - loss: 0.5117 - tp: 2371936.0000 - fp: 1325240.0000 - tn: 38769728.0000 - fn: 2083064.0000 - accuracy: 0.9235 - precision: 0.6416 - recall: 0.5324 - auc: 0.9602 - val_loss: 0.1158 - val_tp: 31825.0000 - val_fp: 7638.0000 - val_tn: 397362.0000 - val_fn: 13175.0000 - val_accuracy: 0.9537 - val_precision: 0.8065 - val_recall: 0.7072 - val_auc: 0.9813\n",
      "Epoch 2/20\n",
      "990/990 [==============================] - 10s 10ms/step - loss: 0.0703 - tp: 3792144.0000 - fp: 382507.0000 - tn: 39712476.0000 - fn: 662856.0000 - accuracy: 0.9765 - precision: 0.9084 - recall: 0.8512 - auc: 0.9948 - val_loss: 0.0437 - val_tp: 42921.0000 - val_fp: 2178.0000 - val_tn: 402822.0000 - val_fn: 2079.0000 - val_accuracy: 0.9905 - val_precision: 0.9517 - val_recall: 0.9538 - val_auc: 0.9984\n",
      "Epoch 3/20\n",
      "990/990 [==============================] - 10s 10ms/step - loss: 0.0310 - tp: 4289013.0000 - fp: 102835.0000 - tn: 39992152.0000 - fn: 165987.0000 - accuracy: 0.9940 - precision: 0.9766 - recall: 0.9627 - auc: 0.9991 - val_loss: 0.0265 - val_tp: 44107.0000 - val_fp: 660.0000 - val_tn: 404340.0000 - val_fn: 893.0000 - val_accuracy: 0.9965 - val_precision: 0.9853 - val_recall: 0.9802 - val_auc: 0.9991\n",
      "Epoch 4/20\n",
      "990/990 [==============================] - 10s 10ms/step - loss: 0.0182 - tp: 4378182.0000 - fp: 47530.0000 - tn: 40047488.0000 - fn: 76818.0000 - accuracy: 0.9972 - precision: 0.9893 - recall: 0.9828 - auc: 0.9996 - val_loss: 0.0158 - val_tp: 44504.0000 - val_fp: 469.0000 - val_tn: 404531.0000 - val_fn: 496.0000 - val_accuracy: 0.9979 - val_precision: 0.9896 - val_recall: 0.9890 - val_auc: 0.9997\n",
      "Epoch 5/20\n",
      "990/990 [==============================] - 10s 10ms/step - loss: 0.0137 - tp: 4403313.0000 - fp: 33804.0000 - tn: 40061176.0000 - fn: 51687.0000 - accuracy: 0.9981 - precision: 0.9924 - recall: 0.9884 - auc: 0.9997 - val_loss: 0.0110 - val_tp: 44704.0000 - val_fp: 194.0000 - val_tn: 404806.0000 - val_fn: 296.0000 - val_accuracy: 0.9989 - val_precision: 0.9957 - val_recall: 0.9934 - val_auc: 0.9998\n",
      "Epoch 6/20\n",
      "990/990 [==============================] - 10s 11ms/step - loss: 0.0122 - tp: 4413198.0000 - fp: 28572.0000 - tn: 40066424.0000 - fn: 41802.0000 - accuracy: 0.9984 - precision: 0.9936 - recall: 0.9906 - auc: 0.9997 - val_loss: 0.0337 - val_tp: 43611.0000 - val_fp: 669.0000 - val_tn: 404331.0000 - val_fn: 1389.0000 - val_accuracy: 0.9954 - val_precision: 0.9849 - val_recall: 0.9691 - val_auc: 0.9979\n",
      "Epoch 7/20\n",
      "990/990 [==============================] - 12s 12ms/step - loss: 0.0119 - tp: 4417783.0000 - fp: 26340.0000 - tn: 40068668.0000 - fn: 37217.0000 - accuracy: 0.9986 - precision: 0.9941 - recall: 0.9916 - auc: 0.9997 - val_loss: 0.0126 - val_tp: 44737.0000 - val_fp: 184.0000 - val_tn: 404816.0000 - val_fn: 263.0000 - val_accuracy: 0.9990 - val_precision: 0.9959 - val_recall: 0.9942 - val_auc: 0.9998\n",
      "Epoch 8/20\n",
      "990/990 [==============================] - 18s 18ms/step - loss: 0.0096 - tp: 4425562.0000 - fp: 21175.0000 - tn: 40073836.0000 - fn: 29438.0000 - accuracy: 0.9989 - precision: 0.9952 - recall: 0.9934 - auc: 0.9998 - val_loss: 0.0070 - val_tp: 44833.0000 - val_fp: 174.0000 - val_tn: 404826.0000 - val_fn: 167.0000 - val_accuracy: 0.9992 - val_precision: 0.9961 - val_recall: 0.9963 - val_auc: 0.9999\n",
      "Epoch 9/20\n",
      "990/990 [==============================] - 17s 17ms/step - loss: 0.0096 - tp: 4426336.0000 - fp: 21285.0000 - tn: 40073724.0000 - fn: 28664.0000 - accuracy: 0.9989 - precision: 0.9952 - recall: 0.9936 - auc: 0.9997 - val_loss: 0.0055 - val_tp: 44871.0000 - val_fp: 67.0000 - val_tn: 404933.0000 - val_fn: 129.0000 - val_accuracy: 0.9996 - val_precision: 0.9985 - val_recall: 0.9971 - val_auc: 0.9999\n",
      "Epoch 10/20\n",
      "990/990 [==============================] - 17s 17ms/step - loss: 0.0076 - tp: 4431697.0000 - fp: 17126.0000 - tn: 40077832.0000 - fn: 23303.0000 - accuracy: 0.9991 - precision: 0.9962 - recall: 0.9948 - auc: 0.9998 - val_loss: 0.0051 - val_tp: 44888.0000 - val_fp: 76.0000 - val_tn: 404924.0000 - val_fn: 112.0000 - val_accuracy: 0.9996 - val_precision: 0.9983 - val_recall: 0.9975 - val_auc: 0.9999\n",
      "Epoch 11/20\n",
      "990/990 [==============================] - 17s 17ms/step - loss: 0.0062 - tp: 4434609.0000 - fp: 15167.0000 - tn: 40079836.0000 - fn: 20391.0000 - accuracy: 0.9992 - precision: 0.9966 - recall: 0.9954 - auc: 0.9998 - val_loss: 0.0044 - val_tp: 44929.0000 - val_fp: 82.0000 - val_tn: 404918.0000 - val_fn: 71.0000 - val_accuracy: 0.9997 - val_precision: 0.9982 - val_recall: 0.9984 - val_auc: 1.0000\n",
      "Epoch 12/20\n",
      "990/990 [==============================] - 17s 17ms/step - loss: 0.0066 - tp: 4434210.0000 - fp: 15759.0000 - tn: 40079220.0000 - fn: 20790.0000 - accuracy: 0.9992 - precision: 0.9965 - recall: 0.9953 - auc: 0.9998 - val_loss: 0.0052 - val_tp: 44844.0000 - val_fp: 95.0000 - val_tn: 404905.0000 - val_fn: 156.0000 - val_accuracy: 0.9994 - val_precision: 0.9979 - val_recall: 0.9965 - val_auc: 0.9999\n",
      "Epoch 13/20\n",
      "990/990 [==============================] - 17s 17ms/step - loss: 0.0054 - tp: 4437038.0000 - fp: 13634.0000 - tn: 40081412.0000 - fn: 17962.0000 - accuracy: 0.9993 - precision: 0.9969 - recall: 0.9960 - auc: 0.9998 - val_loss: 0.0073 - val_tp: 44724.0000 - val_fp: 228.0000 - val_tn: 404772.0000 - val_fn: 276.0000 - val_accuracy: 0.9989 - val_precision: 0.9949 - val_recall: 0.9939 - val_auc: 0.9994\n",
      "Epoch 14/20\n",
      "990/990 [==============================] - 17s 17ms/step - loss: 0.0053 - tp: 4438043.0000 - fp: 12914.0000 - tn: 40082076.0000 - fn: 16957.0000 - accuracy: 0.9993 - precision: 0.9971 - recall: 0.9962 - auc: 0.9998 - val_loss: 0.0046 - val_tp: 44914.0000 - val_fp: 78.0000 - val_tn: 404922.0000 - val_fn: 86.0000 - val_accuracy: 0.9996 - val_precision: 0.9983 - val_recall: 0.9981 - val_auc: 0.9999\n",
      "Epoch 15/20\n",
      "990/990 [==============================] - 17s 17ms/step - loss: 0.0050 - tp: 4439132.0000 - fp: 12292.0000 - tn: 40082728.0000 - fn: 15868.0000 - accuracy: 0.9994 - precision: 0.9972 - recall: 0.9964 - auc: 0.9999 - val_loss: 0.0049 - val_tp: 44800.0000 - val_fp: 90.0000 - val_tn: 404910.0000 - val_fn: 200.0000 - val_accuracy: 0.9994 - val_precision: 0.9980 - val_recall: 0.9956 - val_auc: 0.9998\n",
      "Epoch 16/20\n",
      "990/990 [==============================] - 17s 17ms/step - loss: 0.0049 - tp: 4439568.0000 - fp: 11923.0000 - tn: 40083104.0000 - fn: 15432.0000 - accuracy: 0.9994 - precision: 0.9973 - recall: 0.9965 - auc: 0.9998 - val_loss: 0.0040 - val_tp: 44927.0000 - val_fp: 105.0000 - val_tn: 404895.0000 - val_fn: 73.0000 - val_accuracy: 0.9996 - val_precision: 0.9977 - val_recall: 0.9984 - val_auc: 0.9999\n",
      "Epoch 17/20\n",
      "990/990 [==============================] - 17s 17ms/step - loss: 0.0046 - tp: 4440653.0000 - fp: 11195.0000 - tn: 40083832.0000 - fn: 14347.0000 - accuracy: 0.9994 - precision: 0.9975 - recall: 0.9968 - auc: 0.9999 - val_loss: 0.0061 - val_tp: 44613.0000 - val_fp: 116.0000 - val_tn: 404884.0000 - val_fn: 387.0000 - val_accuracy: 0.9989 - val_precision: 0.9974 - val_recall: 0.9914 - val_auc: 0.9997\n",
      "Epoch 18/20\n",
      "990/990 [==============================] - 17s 17ms/step - loss: 0.0046 - tp: 4441021.0000 - fp: 10955.0000 - tn: 40084052.0000 - fn: 13979.0000 - accuracy: 0.9994 - precision: 0.9975 - recall: 0.9969 - auc: 0.9999 - val_loss: 0.0039 - val_tp: 44914.0000 - val_fp: 72.0000 - val_tn: 404928.0000 - val_fn: 86.0000 - val_accuracy: 0.9996 - val_precision: 0.9984 - val_recall: 0.9981 - val_auc: 0.9999\n",
      "Epoch 19/20\n",
      "990/990 [==============================] - 17s 17ms/step - loss: 0.0044 - tp: 4441665.0000 - fp: 10541.0000 - tn: 40084444.0000 - fn: 13335.0000 - accuracy: 0.9995 - precision: 0.9976 - recall: 0.9970 - auc: 0.9999 - val_loss: 0.0035 - val_tp: 44911.0000 - val_fp: 48.0000 - val_tn: 404952.0000 - val_fn: 89.0000 - val_accuracy: 0.9997 - val_precision: 0.9989 - val_recall: 0.9980 - val_auc: 0.9999\n",
      "Epoch 20/20\n",
      "990/990 [==============================] - 17s 17ms/step - loss: 0.0043 - tp: 4442151.0000 - fp: 10251.0000 - tn: 40084744.0000 - fn: 12849.0000 - accuracy: 0.9995 - precision: 0.9977 - recall: 0.9971 - auc: 0.9999 - val_loss: 0.0030 - val_tp: 44928.0000 - val_fp: 39.0000 - val_tn: 404961.0000 - val_fn: 72.0000 - val_accuracy: 0.9998 - val_precision: 0.9991 - val_recall: 0.9984 - val_auc: 1.0000\n",
      "525/525 [==============================] - 3s 5ms/step - loss: 0.0054 - tp: 150127.0000 - fp: 319.0000 - tn: 1360481.0000 - fn: 1073.0000 - accuracy: 0.9991 - precision: 0.9979 - recall: 0.9929 - auc: 0.9994\n",
      "loss = 0.005379393696784973\n",
      "TP = 150127.0\n",
      "FP = 319.0\n",
      "TN = 1360481.0\n",
      "FN = 1073.0\n",
      "BinaryAccuracy = 0.9990793466567993\n",
      "Precision = 0.9978796243667603\n",
      "Recall = 0.9929034113883972\n",
      "AUC = 0.9994022846221924\n",
      "Model: \"ResNet\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None, 120)]                0         []                            \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 120)                  14520     ['input_1[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization (Batch  (None, 120)                  480       ['dense[0][0]']               \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation (Activation)     (None, 120)                  0         ['batch_normalization[0][0]'] \n",
      "                                                                                                  \n",
      " dense_1 (Dense)             (None, 960)                  116160    ['activation[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_1 (Bat  (None, 960)                  3840      ['dense_1[0][0]']             \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " activation_1 (Activation)   (None, 960)                  0         ['batch_normalization_1[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " dropout (Dropout)           (None, 960)                  0         ['activation_1[0][0]']        \n",
      "                                                                                                  \n",
      " dense_2 (Dense)             (None, 480)                  461280    ['dropout[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_2 (Bat  (None, 480)                  1920      ['dense_2[0][0]']             \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " activation_2 (Activation)   (None, 480)                  0         ['batch_normalization_2[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " dense_3 (Dense)             (None, 240)                  115440    ['activation_2[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_3 (Bat  (None, 240)                  960       ['dense_3[0][0]']             \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " dense_4 (Dense)             (None, 120)                  28920     ['batch_normalization_3[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " batch_normalization_4 (Bat  (None, 120)                  480       ['dense_4[0][0]']             \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " activation_3 (Activation)   (None, 120)                  0         ['batch_normalization_4[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " add (Add)                   (None, 120)                  0         ['activation_3[0][0]',        \n",
      "                                                                     'activation[0][0]']          \n",
      "                                                                                                  \n",
      " dense_5 (Dense)             (None, 960)                  116160    ['add[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_5 (Bat  (None, 960)                  3840      ['dense_5[0][0]']             \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " activation_4 (Activation)   (None, 960)                  0         ['batch_normalization_5[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)         (None, 960)                  0         ['activation_4[0][0]']        \n",
      "                                                                                                  \n",
      " dense_6 (Dense)             (None, 480)                  461280    ['dropout_1[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_6 (Bat  (None, 480)                  1920      ['dense_6[0][0]']             \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " activation_5 (Activation)   (None, 480)                  0         ['batch_normalization_6[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " dense_7 (Dense)             (None, 240)                  115440    ['activation_5[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_7 (Bat  (None, 240)                  960       ['dense_7[0][0]']             \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " dense_8 (Dense)             (None, 120)                  28920     ['batch_normalization_7[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " batch_normalization_8 (Bat  (None, 120)                  480       ['dense_8[0][0]']             \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " activation_6 (Activation)   (None, 120)                  0         ['batch_normalization_8[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " add_1 (Add)                 (None, 120)                  0         ['activation_6[0][0]',        \n",
      "                                                                     'add[0][0]']                 \n",
      "                                                                                                  \n",
      " dense_9 (Dense)             (None, 960)                  116160    ['add_1[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_9 (Bat  (None, 960)                  3840      ['dense_9[0][0]']             \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " activation_7 (Activation)   (None, 960)                  0         ['batch_normalization_9[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)         (None, 960)                  0         ['activation_7[0][0]']        \n",
      "                                                                                                  \n",
      " dense_10 (Dense)            (None, 480)                  461280    ['dropout_2[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_10 (Ba  (None, 480)                  1920      ['dense_10[0][0]']            \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_8 (Activation)   (None, 480)                  0         ['batch_normalization_10[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " dense_11 (Dense)            (None, 240)                  115440    ['activation_8[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_11 (Ba  (None, 240)                  960       ['dense_11[0][0]']            \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " dense_12 (Dense)            (None, 120)                  28920     ['batch_normalization_11[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " batch_normalization_12 (Ba  (None, 120)                  480       ['dense_12[0][0]']            \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_9 (Activation)   (None, 120)                  0         ['batch_normalization_12[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " add_2 (Add)                 (None, 120)                  0         ['activation_9[0][0]',        \n",
      "                                                                     'add_1[0][0]']               \n",
      "                                                                                                  \n",
      " dense_13 (Dense)            (None, 960)                  116160    ['add_2[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_13 (Ba  (None, 960)                  3840      ['dense_13[0][0]']            \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_10 (Activation)  (None, 960)                  0         ['batch_normalization_13[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)         (None, 960)                  0         ['activation_10[0][0]']       \n",
      "                                                                                                  \n",
      " dense_14 (Dense)            (None, 480)                  461280    ['dropout_3[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_14 (Ba  (None, 480)                  1920      ['dense_14[0][0]']            \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_11 (Activation)  (None, 480)                  0         ['batch_normalization_14[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " dense_15 (Dense)            (None, 240)                  115440    ['activation_11[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_15 (Ba  (None, 240)                  960       ['dense_15[0][0]']            \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " dense_16 (Dense)            (None, 120)                  28920     ['batch_normalization_15[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " batch_normalization_16 (Ba  (None, 120)                  480       ['dense_16[0][0]']            \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_12 (Activation)  (None, 120)                  0         ['batch_normalization_16[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " add_3 (Add)                 (None, 120)                  0         ['activation_12[0][0]',       \n",
      "                                                                     'add_2[0][0]']               \n",
      "                                                                                                  \n",
      " flatten (Flatten)           (None, 120)                  0         ['add_3[0][0]']               \n",
      "                                                                                                  \n",
      " dense_17 (Dense)            (None, 90)                   10890     ['flatten[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 2941890 (11.22 MB)\n",
      "Trainable params: 2927250 (11.17 MB)\n",
      "Non-trainable params: 14640 (57.19 KB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = ResNet()\n",
    "\n",
    "# opt = keras.optimizers.Adam(learning_rate=0.0001)\n",
    "\n",
    "model.compile(optimizer=\"Adam\", loss=\"binary_crossentropy\", metrics=metrics)\n",
    "#model.compile(optimizer=\"RMSprop\", loss=\"binary_crossentropy\", metrics=metrics)\n",
    "\n",
    "batch = 500\n",
    "epoch = 20\n",
    "\n",
    "history_1 = model.fit(Training_Data, Training_Labels, validation_split=0.01, epochs=epoch, batch_size=batch,\n",
    "                      shuffle=True, verbose=1)\n",
    "preds_1 = model.evaluate(Testing_Data, Testing_Labels)\n",
    "\n",
    "\n",
    "\n",
    "print(\"loss = \" + str(preds_1[0]))\n",
    "print(\"TP = \" + str(preds_1[1]))\n",
    "print(\"FP = \" + str(preds_1[2]))\n",
    "print(\"TN = \" + str(preds_1[3]))\n",
    "print(\"FN = \" + str(preds_1[4]))\n",
    "print(\"BinaryAccuracy = \" + str(preds_1[5]))\n",
    "print(\"Precision = \" + str(preds_1[6]))\n",
    "print(\"Recall = \" + str(preds_1[7]))\n",
    "print(\"AUC = \" + str(preds_1[8]))\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef59dcf-e19c-49b2-a2fe-60994268077e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
